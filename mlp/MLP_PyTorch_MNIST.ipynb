{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CONFIG"
      ],
      "metadata": {
        "id": "j37dUO-0PNvZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOxEkM6TO1Qv",
        "outputId": "8e0500c8-d0d9-4770-9682-6ff523a6fe84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov  8 06:13:13 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVp3L5O-PCcA",
        "outputId": "918847f7-a2ca-472f-b46d-e7e247596fbf"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.1.0+cu118\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, sympy, triton, typing-extensions\n",
            "Required-by: fastai, torchaudio, torchdata, torchtext, torchvision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as Data\n",
        "\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "relkyEUhPCZd"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(101)\n",
        "\n",
        "print(\"Using torch\", torch.__version__)\n",
        "print(f\"Is the GPU available? {torch.cuda.is_available()}\")\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Device\", device)\n",
        "\n",
        "# GPU operations have a separate seed we also want to set\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Additionally, some operations on a GPU are implemented stochastic for efficiency\n",
        "# We want to ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJS-fVdUP3Q6",
        "outputId": "24215f81-0ea4-49d7-e708-d085f47f5e67"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using torch 2.1.0+cu118\n",
            "Is the GPU available? True\n",
            "Device cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST"
      ],
      "metadata": {
        "id": "ecc3PI3RSg8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "# MNIST Dataset\n",
        "train_dataset = dsets.MNIST(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "\n",
        "test_dataset = dsets.MNIST(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "#test_x = Variable(torch.unsqueeze(test_dataset.data, dim=1)).type(torch.FloatTensor)\n",
        "test_x = torch.unsqueeze(test_dataset.data, dim=1).type(torch.FloatTensor)\n",
        "test_y = test_dataset.targets"
      ],
      "metadata": {
        "id": "aCJjmuPBSiiU"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN"
      ],
      "metadata": {
        "id": "nDe0ErtaQWM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "xawgYSVWQYiO"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rightness(predictions, labels):\n",
        "    '''\n",
        "    Calculate the prediction error rate\n",
        "    1. \"predictions\" gives a series of predictions, which is a  \"batch_size\" x \"num_classes\" matrix.\n",
        "    2. \"labels\" are correct answer\n",
        "    '''\n",
        "    pred = torch.max(predictions.data, 1)[1]\n",
        "    # For the first dimension of every row (every image), ouput the index of the biggest elements in every row.\n",
        "    rights = pred.eq(labels.data.view_as(pred)).sum()\n",
        "    # Compare the indexs with categories in \"labels\", and get the accumulated correct numbers.\n",
        "    return rights, len(labels)\n",
        "    # Return the correct numbers and all samples.\n"
      ],
      "metadata": {
        "id": "KtbPrWqKVLua"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer):\n",
        "  record = [] # A container recording the training accuracies\n",
        "\n",
        "  train_start_time = time.time()\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      train_rights = [] # Record the training accuracies\n",
        "\n",
        "      for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "          # Convert torch tensor to Variable\n",
        "          #images = Variable(images.view(-1, 28*28))\n",
        "          images = images.view(-1, 28*28)\n",
        "          #labels = Variable(labels)\n",
        "          labels = labels\n",
        "\n",
        "          MLP.train() # Indicate the model that it's training time\n",
        "\n",
        "          # Forward + Backward + Optimizer\n",
        "          optimizer.zero_grad()  # zero the gradient buffer\n",
        "          #outputs = net(images)\n",
        "          outputs = MLP(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          right = rightness(outputs, labels) # (outputs, labels) = (correct numbers, all samples)\n",
        "          train_rights.append(right)\n",
        "\n",
        "          if (i+1) % 200 == 0:\n",
        "\n",
        "            MLP.eval() # Indicate the model that it's validation/test time\n",
        "\n",
        "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
        "            train_accuracy = 100. * train_r[0].numpy() / train_r[1]\n",
        "            total_step = len(train_dataset)//batch_size\n",
        "\n",
        "            print ('Epoch [{:d}/{:d}], Step [{:3d}/{:d}], Loss: {:.4f} | training accuracy: {:5.2f} %'.format(\n",
        "                  epoch+1, num_epochs, i+1, total_step, loss.data, train_accuracy))\n",
        "\n",
        "            record.append(100 - 100. * train_r[0] / train_r[1])\n",
        "  train_end_time = time.time()\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in test_loader:\n",
        "      #images = Variable(images.view(-1, 28*28))\n",
        "      images = images.view(-1, 28*28)\n",
        "      outputs = MLP(images)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum()\n",
        "\n",
        "  print('Accuracy of the MLP on the 60000 training images: %.4f %%' %\n",
        "        (100 - record[-1]))\n",
        "\n",
        "  print('Accuracy of the MLP on the 10000 test     images: %.4f %%' %\n",
        "        (100 * torch.true_divide(correct,total)))\n",
        "\n",
        "  return [MLP.hidden_size, num_epochs, batch_size, learning_rate, type(criterion), type(optimizer), '%.4f %%' %(100 - record[-1]), '%.4f %%' %(100 * torch.true_divide(correct,total)), f\"{(train_end_time - train_start_time):6.5f}s\"]"
      ],
      "metadata": {
        "id": "ah2u-17iVlzZ"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testes"
      ],
      "metadata": {
        "id": "tiz-plDEak_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = []"
      ],
      "metadata": {
        "id": "XBNUMjivakOb"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiYuLtz_WXfn",
        "outputId": "a707f927-0627-4a24-fcc2-3b483dc5e4a8"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [200/468], Loss: 2.2560 | training accuracy: 17.14 %\n",
            "Epoch [1/5], Step [400/468], Loss: 2.2050 | training accuracy: 25.01 %\n",
            "Epoch [2/5], Step [200/468], Loss: 2.1560 | training accuracy: 51.09 %\n",
            "Epoch [2/5], Step [400/468], Loss: 2.0959 | training accuracy: 55.07 %\n",
            "Epoch [3/5], Step [200/468], Loss: 2.0192 | training accuracy: 66.54 %\n",
            "Epoch [3/5], Step [400/468], Loss: 1.9621 | training accuracy: 67.95 %\n",
            "Epoch [4/5], Step [200/468], Loss: 1.8917 | training accuracy: 71.90 %\n",
            "Epoch [4/5], Step [400/468], Loss: 1.7818 | training accuracy: 72.32 %\n",
            "Epoch [5/5], Step [200/468], Loss: 1.6827 | training accuracy: 74.11 %\n",
            "Epoch [5/5], Step [400/468], Loss: 1.6325 | training accuracy: 74.40 %\n",
            "Accuracy of the MLP on the 60000 training images: 74.3965 %\n",
            "Accuracy of the MLP on the 10000 test     images: 76.0200 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y5Xi_cHYwY2",
        "outputId": "fac3ec0f-cfe2-4990-f750-c89d48618cf4"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [200/468], Loss: 0.3535 | training accuracy: 87.27 %\n",
            "Epoch [1/5], Step [400/468], Loss: 0.1768 | training accuracy: 90.57 %\n",
            "Epoch [2/5], Step [200/468], Loss: 0.1069 | training accuracy: 95.98 %\n",
            "Epoch [2/5], Step [400/468], Loss: 0.0822 | training accuracy: 96.21 %\n",
            "Epoch [3/5], Step [200/468], Loss: 0.0899 | training accuracy: 97.39 %\n",
            "Epoch [3/5], Step [400/468], Loss: 0.1696 | training accuracy: 97.50 %\n",
            "Epoch [4/5], Step [200/468], Loss: 0.0324 | training accuracy: 98.26 %\n",
            "Epoch [4/5], Step [400/468], Loss: 0.0474 | training accuracy: 98.18 %\n",
            "Epoch [5/5], Step [200/468], Loss: 0.0782 | training accuracy: 98.72 %\n",
            "Epoch [5/5], Step [400/468], Loss: 0.0514 | training accuracy: 98.76 %\n",
            "Accuracy of the MLP on the 60000 training images: 98.7559 %\n",
            "Accuracy of the MLP on the 10000 test     images: 97.9100 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHpO5Ni8btHl",
        "outputId": "9936dded-9c9f-4b51-9326-c8e0d2490c3f"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [200/468], Loss: 1.7441 | training accuracy: 56.15 %\n",
            "Epoch [1/5], Step [400/468], Loss: 1.1253 | training accuracy: 66.00 %\n",
            "Epoch [2/5], Step [200/468], Loss: 0.7091 | training accuracy: 82.97 %\n",
            "Epoch [2/5], Step [400/468], Loss: 0.6235 | training accuracy: 83.91 %\n",
            "Epoch [3/5], Step [200/468], Loss: 0.5103 | training accuracy: 86.62 %\n",
            "Epoch [3/5], Step [400/468], Loss: 0.4473 | training accuracy: 87.09 %\n",
            "Epoch [4/5], Step [200/468], Loss: 0.4440 | training accuracy: 87.70 %\n",
            "Epoch [4/5], Step [400/468], Loss: 0.3815 | training accuracy: 88.22 %\n",
            "Epoch [5/5], Step [200/468], Loss: 0.3546 | training accuracy: 88.80 %\n",
            "Epoch [5/5], Step [400/468], Loss: 0.3500 | training accuracy: 89.17 %\n",
            "Accuracy of the MLP on the 60000 training images: 89.1738 %\n",
            "Accuracy of the MLP on the 10000 test     images: 90.1400 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 500\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaCBsy2acOxB",
        "outputId": "8072af24-9ce3-4166-cdeb-dad910642759"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [200/468], Loss: 0.0997 | training accuracy: 91.09 %\n",
            "Epoch [1/5], Step [400/468], Loss: 0.3076 | training accuracy: 93.17 %\n",
            "Epoch [2/5], Step [200/468], Loss: 0.1349 | training accuracy: 96.75 %\n",
            "Epoch [2/5], Step [400/468], Loss: 0.1532 | training accuracy: 96.65 %\n",
            "Epoch [3/5], Step [200/468], Loss: 0.0608 | training accuracy: 97.52 %\n",
            "Epoch [3/5], Step [400/468], Loss: 0.0735 | training accuracy: 97.49 %\n",
            "Epoch [4/5], Step [200/468], Loss: 0.0993 | training accuracy: 97.86 %\n",
            "Epoch [4/5], Step [400/468], Loss: 0.3198 | training accuracy: 97.75 %\n",
            "Epoch [5/5], Step [200/468], Loss: 0.0646 | training accuracy: 97.95 %\n",
            "Epoch [5/5], Step [400/468], Loss: 0.0885 | training accuracy: 97.96 %\n",
            "Accuracy of the MLP on the 60000 training images: 97.9570 %\n",
            "Accuracy of the MLP on the 10000 test     images: 97.3500 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 256\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNBJ66RyckSx",
        "outputId": "6ae12f86-f9ee-4eed-9fbd-d34def3c92ba"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [200/468], Loss: 2.2707 | training accuracy: 13.31 %\n",
            "Epoch [1/5], Step [400/468], Loss: 2.2388 | training accuracy: 18.28 %\n",
            "Epoch [2/5], Step [200/468], Loss: 2.1884 | training accuracy: 36.75 %\n",
            "Epoch [2/5], Step [400/468], Loss: 2.1406 | training accuracy: 42.46 %\n",
            "Epoch [3/5], Step [200/468], Loss: 2.0722 | training accuracy: 59.95 %\n",
            "Epoch [3/5], Step [400/468], Loss: 2.0131 | training accuracy: 62.79 %\n",
            "Epoch [4/5], Step [200/468], Loss: 1.9428 | training accuracy: 69.64 %\n",
            "Epoch [4/5], Step [400/468], Loss: 1.8804 | training accuracy: 70.36 %\n",
            "Epoch [5/5], Step [200/468], Loss: 1.7970 | training accuracy: 73.28 %\n",
            "Epoch [5/5], Step [400/468], Loss: 1.7314 | training accuracy: 73.74 %\n",
            "Accuracy of the MLP on the 60000 training images: 73.7422 %\n",
            "Accuracy of the MLP on the 10000 test     images: 75.5300 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 256\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FrGEba4ezBc",
        "outputId": "89506fb6-0ecf-4f88-a324-7740d2853afb"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [200/468], Loss: 0.1676 | training accuracy: 91.14 %\n",
            "Epoch [1/5], Step [400/468], Loss: 0.2404 | training accuracy: 93.06 %\n",
            "Epoch [2/5], Step [200/468], Loss: 0.0601 | training accuracy: 96.49 %\n",
            "Epoch [2/5], Step [400/468], Loss: 0.0583 | training accuracy: 96.61 %\n",
            "Epoch [3/5], Step [200/468], Loss: 0.0326 | training accuracy: 97.52 %\n",
            "Epoch [3/5], Step [400/468], Loss: 0.0422 | training accuracy: 97.46 %\n",
            "Epoch [4/5], Step [200/468], Loss: 0.0262 | training accuracy: 97.93 %\n",
            "Epoch [4/5], Step [400/468], Loss: 0.1305 | training accuracy: 97.75 %\n",
            "Epoch [5/5], Step [200/468], Loss: 0.0304 | training accuracy: 98.11 %\n",
            "Epoch [5/5], Step [400/468], Loss: 0.1057 | training accuracy: 97.97 %\n",
            "Accuracy of the MLP on the 60000 training images: 97.9746 %\n",
            "Accuracy of the MLP on the 10000 test     images: 96.9900 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 256\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adagrad(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJXWnu3zfKtT",
        "outputId": "e8f2499d-58d6-4cc2-99b2-c006630fe717"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [200/468], Loss: 0.2997 | training accuracy: 88.65 %\n",
            "Epoch [1/5], Step [400/468], Loss: 0.2161 | training accuracy: 91.19 %\n",
            "Epoch [2/5], Step [200/468], Loss: 0.1248 | training accuracy: 95.21 %\n",
            "Epoch [2/5], Step [400/468], Loss: 0.1197 | training accuracy: 95.35 %\n",
            "Epoch [3/5], Step [200/468], Loss: 0.1161 | training accuracy: 96.19 %\n",
            "Epoch [3/5], Step [400/468], Loss: 0.1516 | training accuracy: 96.27 %\n",
            "Epoch [4/5], Step [200/468], Loss: 0.0521 | training accuracy: 96.73 %\n",
            "Epoch [4/5], Step [400/468], Loss: 0.1526 | training accuracy: 96.74 %\n",
            "Epoch [5/5], Step [200/468], Loss: 0.1472 | training accuracy: 97.16 %\n",
            "Epoch [5/5], Step [400/468], Loss: 0.1113 | training accuracy: 97.12 %\n",
            "Accuracy of the MLP on the 60000 training images: 97.1172 %\n",
            "Accuracy of the MLP on the 10000 test     images: 96.8400 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 128\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOjvJfpZfhw5",
        "outputId": "e78ab6d5-6bf4-4b00-d584-ca258abf3a71"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [200/468], Loss: 0.1212 | training accuracy: 90.25 %\n",
            "Epoch [1/5], Step [400/468], Loss: 0.1105 | training accuracy: 92.84 %\n",
            "Epoch [2/5], Step [200/468], Loss: 0.0485 | training accuracy: 96.61 %\n",
            "Epoch [2/5], Step [400/468], Loss: 0.0641 | training accuracy: 96.57 %\n",
            "Epoch [3/5], Step [200/468], Loss: 0.0662 | training accuracy: 97.36 %\n",
            "Epoch [3/5], Step [400/468], Loss: 0.1493 | training accuracy: 97.30 %\n",
            "Epoch [4/5], Step [200/468], Loss: 0.0106 | training accuracy: 97.89 %\n",
            "Epoch [4/5], Step [400/468], Loss: 0.1161 | training accuracy: 97.89 %\n",
            "Epoch [5/5], Step [200/468], Loss: 0.0536 | training accuracy: 98.00 %\n",
            "Epoch [5/5], Step [400/468], Loss: 0.0242 | training accuracy: 97.91 %\n",
            "Accuracy of the MLP on the 60000 training images: 97.9102 %\n",
            "Accuracy of the MLP on the 10000 test     images: 96.5700 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 64\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO74jrjOfy1p",
        "outputId": "afb487c9-6de9-437c-ce9c-25c8711b1c11"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [200/468], Loss: 0.1517 | training accuracy: 89.80 %\n",
            "Epoch [1/5], Step [400/468], Loss: 0.2179 | training accuracy: 92.19 %\n",
            "Epoch [2/5], Step [200/468], Loss: 0.2122 | training accuracy: 96.11 %\n",
            "Epoch [2/5], Step [400/468], Loss: 0.2623 | training accuracy: 96.28 %\n",
            "Epoch [3/5], Step [200/468], Loss: 0.1208 | training accuracy: 96.89 %\n",
            "Epoch [3/5], Step [400/468], Loss: 0.2268 | training accuracy: 96.94 %\n",
            "Epoch [4/5], Step [200/468], Loss: 0.0714 | training accuracy: 97.59 %\n",
            "Epoch [4/5], Step [400/468], Loss: 0.0512 | training accuracy: 97.54 %\n",
            "Epoch [5/5], Step [200/468], Loss: 0.0471 | training accuracy: 97.87 %\n",
            "Epoch [5/5], Step [400/468], Loss: 0.0990 | training accuracy: 97.64 %\n",
            "Accuracy of the MLP on the 60000 training images: 97.6426 %\n",
            "Accuracy of the MLP on the 10000 test     images: 96.6700 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 64\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1VPer3ygKDp",
        "outputId": "f40bd284-b976-463d-eb49-a5cd449ab97e"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [200/468], Loss: 0.1471 | training accuracy: 89.57 %\n",
            "Epoch [1/10], Step [400/468], Loss: 0.1946 | training accuracy: 92.17 %\n",
            "Epoch [2/10], Step [200/468], Loss: 0.1131 | training accuracy: 96.27 %\n",
            "Epoch [2/10], Step [400/468], Loss: 0.0689 | training accuracy: 96.34 %\n",
            "Epoch [3/10], Step [200/468], Loss: 0.1179 | training accuracy: 97.04 %\n",
            "Epoch [3/10], Step [400/468], Loss: 0.2260 | training accuracy: 97.00 %\n",
            "Epoch [4/10], Step [200/468], Loss: 0.0819 | training accuracy: 97.43 %\n",
            "Epoch [4/10], Step [400/468], Loss: 0.1080 | training accuracy: 97.37 %\n",
            "Epoch [5/10], Step [200/468], Loss: 0.1147 | training accuracy: 97.83 %\n",
            "Epoch [5/10], Step [400/468], Loss: 0.0570 | training accuracy: 97.72 %\n",
            "Epoch [6/10], Step [200/468], Loss: 0.0421 | training accuracy: 98.05 %\n",
            "Epoch [6/10], Step [400/468], Loss: 0.1018 | training accuracy: 98.01 %\n",
            "Epoch [7/10], Step [200/468], Loss: 0.0930 | training accuracy: 98.30 %\n",
            "Epoch [7/10], Step [400/468], Loss: 0.1055 | training accuracy: 98.13 %\n",
            "Epoch [8/10], Step [200/468], Loss: 0.0830 | training accuracy: 98.19 %\n",
            "Epoch [8/10], Step [400/468], Loss: 0.0582 | training accuracy: 98.07 %\n",
            "Epoch [9/10], Step [200/468], Loss: 0.1029 | training accuracy: 98.40 %\n",
            "Epoch [9/10], Step [400/468], Loss: 0.0660 | training accuracy: 98.24 %\n",
            "Epoch [10/10], Step [200/468], Loss: 0.0579 | training accuracy: 98.62 %\n",
            "Epoch [10/10], Step [400/468], Loss: 0.0128 | training accuracy: 98.57 %\n",
            "Accuracy of the MLP on the 60000 training images: 98.5664 %\n",
            "Accuracy of the MLP on the 10000 test     images: 97.1400 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 15\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 64\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eiw7efy1giDx",
        "outputId": "898d571e-907b-4eee-85e3-d450d3a35b95"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Step [200/468], Loss: 0.2347 | training accuracy: 89.41 %\n",
            "Epoch [1/15], Step [400/468], Loss: 0.1045 | training accuracy: 92.15 %\n",
            "Epoch [2/15], Step [200/468], Loss: 0.0719 | training accuracy: 96.21 %\n",
            "Epoch [2/15], Step [400/468], Loss: 0.1264 | training accuracy: 96.32 %\n",
            "Epoch [3/15], Step [200/468], Loss: 0.0997 | training accuracy: 97.17 %\n",
            "Epoch [3/15], Step [400/468], Loss: 0.0317 | training accuracy: 97.11 %\n",
            "Epoch [4/15], Step [200/468], Loss: 0.0911 | training accuracy: 97.45 %\n",
            "Epoch [4/15], Step [400/468], Loss: 0.1379 | training accuracy: 97.46 %\n",
            "Epoch [5/15], Step [200/468], Loss: 0.0518 | training accuracy: 97.88 %\n",
            "Epoch [5/15], Step [400/468], Loss: 0.0848 | training accuracy: 97.77 %\n",
            "Epoch [6/15], Step [200/468], Loss: 0.0401 | training accuracy: 98.12 %\n",
            "Epoch [6/15], Step [400/468], Loss: 0.1488 | training accuracy: 97.86 %\n",
            "Epoch [7/15], Step [200/468], Loss: 0.0456 | training accuracy: 98.37 %\n",
            "Epoch [7/15], Step [400/468], Loss: 0.1296 | training accuracy: 98.14 %\n",
            "Epoch [8/15], Step [200/468], Loss: 0.0624 | training accuracy: 98.29 %\n",
            "Epoch [8/15], Step [400/468], Loss: 0.0560 | training accuracy: 98.20 %\n",
            "Epoch [9/15], Step [200/468], Loss: 0.0945 | training accuracy: 98.49 %\n",
            "Epoch [9/15], Step [400/468], Loss: 0.0968 | training accuracy: 98.38 %\n",
            "Epoch [10/15], Step [200/468], Loss: 0.0353 | training accuracy: 98.50 %\n",
            "Epoch [10/15], Step [400/468], Loss: 0.1187 | training accuracy: 98.43 %\n",
            "Epoch [11/15], Step [200/468], Loss: 0.0383 | training accuracy: 98.59 %\n",
            "Epoch [11/15], Step [400/468], Loss: 0.0140 | training accuracy: 98.53 %\n",
            "Epoch [12/15], Step [200/468], Loss: 0.0257 | training accuracy: 98.58 %\n",
            "Epoch [12/15], Step [400/468], Loss: 0.0562 | training accuracy: 98.55 %\n",
            "Epoch [13/15], Step [200/468], Loss: 0.0001 | training accuracy: 98.92 %\n",
            "Epoch [13/15], Step [400/468], Loss: 0.0036 | training accuracy: 98.70 %\n",
            "Epoch [14/15], Step [200/468], Loss: 0.0062 | training accuracy: 98.73 %\n",
            "Epoch [14/15], Step [400/468], Loss: 0.0793 | training accuracy: 98.59 %\n",
            "Epoch [15/15], Step [200/468], Loss: 0.0556 | training accuracy: 98.84 %\n",
            "Epoch [15/15], Step [400/468], Loss: 0.0617 | training accuracy: 98.76 %\n",
            "Accuracy of the MLP on the 60000 training images: 98.7598 %\n",
            "Accuracy of the MLP on the 10000 test     images: 96.9900 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 1028\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sUPBXHlhD3e",
        "outputId": "149f1589-00a8-4923-e094-fa231e98e7ea"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [200/468], Loss: 0.3321 | training accuracy: 90.83 %\n",
            "Epoch [1/2], Step [400/468], Loss: 0.2617 | training accuracy: 93.06 %\n",
            "Epoch [2/2], Step [200/468], Loss: 0.0788 | training accuracy: 96.56 %\n",
            "Epoch [2/2], Step [400/468], Loss: 0.2429 | training accuracy: 96.59 %\n",
            "Accuracy of the MLP on the 60000 training images: 96.5938 %\n",
            "Accuracy of the MLP on the 10000 test     images: 96.8300 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "batch_size = 64\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 1028\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W670YRPwhV3t",
        "outputId": "428b5337-780d-4504-b62b-6f9c3642bae6"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [200/937], Loss: 0.0960 | training accuracy: 90.68 %\n",
            "Epoch [1/2], Step [400/937], Loss: 0.1848 | training accuracy: 93.07 %\n",
            "Epoch [2/2], Step [200/937], Loss: 0.2602 | training accuracy: 96.59 %\n",
            "Epoch [2/2], Step [400/937], Loss: 0.1539 | training accuracy: 96.69 %\n",
            "Accuracy of the MLP on the 60000 training images: 96.6875 %\n",
            "Accuracy of the MLP on the 10000 test     images: 96.8500 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "batch_size = 512\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 128\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TdmTC-8hiuq",
        "outputId": "bf0d7761-460b-45a1-a4a0-948ce41d1327"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [200/117], Loss: 0.2271 | training accuracy: 90.45 %\n",
            "Epoch [1/10], Step [400/117], Loss: 0.0924 | training accuracy: 92.74 %\n",
            "Epoch [2/10], Step [200/117], Loss: 0.0911 | training accuracy: 96.72 %\n",
            "Epoch [2/10], Step [400/117], Loss: 0.0606 | training accuracy: 96.63 %\n",
            "Epoch [3/10], Step [200/117], Loss: 0.1783 | training accuracy: 97.36 %\n",
            "Epoch [3/10], Step [400/117], Loss: 0.0818 | training accuracy: 97.38 %\n",
            "Epoch [4/10], Step [200/117], Loss: 0.0904 | training accuracy: 97.89 %\n",
            "Epoch [4/10], Step [400/117], Loss: 0.0917 | training accuracy: 97.77 %\n",
            "Epoch [5/10], Step [200/117], Loss: 0.0746 | training accuracy: 97.96 %\n",
            "Epoch [5/10], Step [400/117], Loss: 0.0690 | training accuracy: 98.00 %\n",
            "Epoch [6/10], Step [200/117], Loss: 0.0573 | training accuracy: 98.18 %\n",
            "Epoch [6/10], Step [400/117], Loss: 0.1043 | training accuracy: 98.05 %\n",
            "Epoch [7/10], Step [200/117], Loss: 0.0847 | training accuracy: 98.63 %\n",
            "Epoch [7/10], Step [400/117], Loss: 0.0215 | training accuracy: 98.53 %\n",
            "Epoch [8/10], Step [200/117], Loss: 0.0737 | training accuracy: 98.48 %\n",
            "Epoch [8/10], Step [400/117], Loss: 0.1006 | training accuracy: 98.31 %\n",
            "Epoch [9/10], Step [200/117], Loss: 0.0174 | training accuracy: 98.63 %\n",
            "Epoch [9/10], Step [400/117], Loss: 0.0082 | training accuracy: 98.57 %\n",
            "Epoch [10/10], Step [200/117], Loss: 0.0193 | training accuracy: 98.79 %\n",
            "Epoch [10/10], Step [400/117], Loss: 0.0092 | training accuracy: 98.61 %\n",
            "Accuracy of the MLP on the 60000 training images: 98.6133 %\n",
            "Accuracy of the MLP on the 10000 test     images: 97.2400 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 64\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RMiqLZQh93C",
        "outputId": "05eb315f-b829-40e9-887e-d2c0428b84a8"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [200/1875], Loss: 0.1858 | training accuracy: 89.31 %\n",
            "Epoch [1/10], Step [400/1875], Loss: 0.1679 | training accuracy: 91.95 %\n",
            "Epoch [2/10], Step [200/1875], Loss: 0.0926 | training accuracy: 95.86 %\n",
            "Epoch [2/10], Step [400/1875], Loss: 0.1006 | training accuracy: 96.23 %\n",
            "Epoch [3/10], Step [200/1875], Loss: 0.0301 | training accuracy: 97.22 %\n",
            "Epoch [3/10], Step [400/1875], Loss: 0.0239 | training accuracy: 97.01 %\n",
            "Epoch [4/10], Step [200/1875], Loss: 0.1009 | training accuracy: 97.48 %\n",
            "Epoch [4/10], Step [400/1875], Loss: 0.0168 | training accuracy: 97.39 %\n",
            "Epoch [5/10], Step [200/1875], Loss: 0.0912 | training accuracy: 97.77 %\n",
            "Epoch [5/10], Step [400/1875], Loss: 0.0363 | training accuracy: 97.64 %\n",
            "Epoch [6/10], Step [200/1875], Loss: 0.1207 | training accuracy: 97.95 %\n",
            "Epoch [6/10], Step [400/1875], Loss: 0.0725 | training accuracy: 97.95 %\n",
            "Epoch [7/10], Step [200/1875], Loss: 0.0219 | training accuracy: 98.32 %\n",
            "Epoch [7/10], Step [400/1875], Loss: 0.0175 | training accuracy: 98.07 %\n",
            "Epoch [8/10], Step [200/1875], Loss: 0.0603 | training accuracy: 98.28 %\n",
            "Epoch [8/10], Step [400/1875], Loss: 0.0501 | training accuracy: 98.15 %\n",
            "Epoch [9/10], Step [200/1875], Loss: 0.0533 | training accuracy: 98.40 %\n",
            "Epoch [9/10], Step [400/1875], Loss: 0.1018 | training accuracy: 98.31 %\n",
            "Epoch [10/10], Step [200/1875], Loss: 0.0484 | training accuracy: 98.47 %\n",
            "Epoch [10/10], Step [400/1875], Loss: 0.0340 | training accuracy: 98.26 %\n",
            "Accuracy of the MLP on the 60000 training images: 98.2637 %\n",
            "Accuracy of the MLP on the 10000 test     images: 96.8100 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "batch_size = 256\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 128\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHC9WABzihXW",
        "outputId": "2678f610-5255-47e5-d721-e87e0eca4a6c"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Step [200/234], Loss: 0.1772 | training accuracy: 90.68 %\n",
            "Epoch [1/30], Step [400/234], Loss: 0.0578 | training accuracy: 92.93 %\n",
            "Epoch [2/30], Step [200/234], Loss: 0.0585 | training accuracy: 96.70 %\n",
            "Epoch [2/30], Step [400/234], Loss: 0.1038 | training accuracy: 96.61 %\n",
            "Epoch [3/30], Step [200/234], Loss: 0.0422 | training accuracy: 97.44 %\n",
            "Epoch [3/30], Step [400/234], Loss: 0.0669 | training accuracy: 97.31 %\n",
            "Epoch [4/30], Step [200/234], Loss: 0.0510 | training accuracy: 97.70 %\n",
            "Epoch [4/30], Step [400/234], Loss: 0.0247 | training accuracy: 97.64 %\n",
            "Epoch [5/30], Step [200/234], Loss: 0.0315 | training accuracy: 98.09 %\n",
            "Epoch [5/30], Step [400/234], Loss: 0.0476 | training accuracy: 97.95 %\n",
            "Epoch [6/30], Step [200/234], Loss: 0.1142 | training accuracy: 98.34 %\n",
            "Epoch [6/30], Step [400/234], Loss: 0.0270 | training accuracy: 98.22 %\n",
            "Epoch [7/30], Step [200/234], Loss: 0.0911 | training accuracy: 98.46 %\n",
            "Epoch [7/30], Step [400/234], Loss: 0.0501 | training accuracy: 98.21 %\n",
            "Epoch [8/30], Step [200/234], Loss: 0.0632 | training accuracy: 98.59 %\n",
            "Epoch [8/30], Step [400/234], Loss: 0.0271 | training accuracy: 98.42 %\n",
            "Epoch [9/30], Step [200/234], Loss: 0.0802 | training accuracy: 98.76 %\n",
            "Epoch [9/30], Step [400/234], Loss: 0.0255 | training accuracy: 98.65 %\n",
            "Epoch [10/30], Step [200/234], Loss: 0.2683 | training accuracy: 98.74 %\n",
            "Epoch [10/30], Step [400/234], Loss: 0.0831 | training accuracy: 98.68 %\n",
            "Epoch [11/30], Step [200/234], Loss: 0.1226 | training accuracy: 98.86 %\n",
            "Epoch [11/30], Step [400/234], Loss: 0.0014 | training accuracy: 98.74 %\n",
            "Epoch [12/30], Step [200/234], Loss: 0.0546 | training accuracy: 98.72 %\n",
            "Epoch [12/30], Step [400/234], Loss: 0.0642 | training accuracy: 98.70 %\n",
            "Epoch [13/30], Step [200/234], Loss: 0.0134 | training accuracy: 98.91 %\n",
            "Epoch [13/30], Step [400/234], Loss: 0.0662 | training accuracy: 98.85 %\n",
            "Epoch [14/30], Step [200/234], Loss: 0.0328 | training accuracy: 98.95 %\n",
            "Epoch [14/30], Step [400/234], Loss: 0.1531 | training accuracy: 98.81 %\n",
            "Epoch [15/30], Step [200/234], Loss: 0.0259 | training accuracy: 99.12 %\n",
            "Epoch [15/30], Step [400/234], Loss: 0.0507 | training accuracy: 99.03 %\n",
            "Epoch [16/30], Step [200/234], Loss: 0.1353 | training accuracy: 98.92 %\n",
            "Epoch [16/30], Step [400/234], Loss: 0.0474 | training accuracy: 98.83 %\n",
            "Epoch [17/30], Step [200/234], Loss: 0.0087 | training accuracy: 98.87 %\n",
            "Epoch [17/30], Step [400/234], Loss: 0.0751 | training accuracy: 98.99 %\n",
            "Epoch [18/30], Step [200/234], Loss: 0.0376 | training accuracy: 99.21 %\n",
            "Epoch [18/30], Step [400/234], Loss: 0.0035 | training accuracy: 99.21 %\n",
            "Epoch [19/30], Step [200/234], Loss: 0.3080 | training accuracy: 99.09 %\n",
            "Epoch [19/30], Step [400/234], Loss: 0.0019 | training accuracy: 99.08 %\n",
            "Epoch [20/30], Step [200/234], Loss: 0.0484 | training accuracy: 99.18 %\n",
            "Epoch [20/30], Step [400/234], Loss: 0.0001 | training accuracy: 99.23 %\n",
            "Epoch [21/30], Step [200/234], Loss: 0.0104 | training accuracy: 99.27 %\n",
            "Epoch [21/30], Step [400/234], Loss: 0.0041 | training accuracy: 99.05 %\n",
            "Epoch [22/30], Step [200/234], Loss: 0.0258 | training accuracy: 99.18 %\n",
            "Epoch [22/30], Step [400/234], Loss: 0.0096 | training accuracy: 99.19 %\n",
            "Epoch [23/30], Step [200/234], Loss: 0.0529 | training accuracy: 99.19 %\n",
            "Epoch [23/30], Step [400/234], Loss: 0.0005 | training accuracy: 99.19 %\n",
            "Epoch [24/30], Step [200/234], Loss: 0.0000 | training accuracy: 99.38 %\n",
            "Epoch [24/30], Step [400/234], Loss: 0.0016 | training accuracy: 99.31 %\n",
            "Epoch [25/30], Step [200/234], Loss: 0.0008 | training accuracy: 99.29 %\n",
            "Epoch [25/30], Step [400/234], Loss: 0.1025 | training accuracy: 99.26 %\n",
            "Epoch [26/30], Step [200/234], Loss: 0.1522 | training accuracy: 99.41 %\n",
            "Epoch [26/30], Step [400/234], Loss: 0.0082 | training accuracy: 99.40 %\n",
            "Epoch [27/30], Step [200/234], Loss: 0.0262 | training accuracy: 99.48 %\n",
            "Epoch [27/30], Step [400/234], Loss: 0.0144 | training accuracy: 99.47 %\n",
            "Epoch [28/30], Step [200/234], Loss: 0.0001 | training accuracy: 99.36 %\n",
            "Epoch [28/30], Step [400/234], Loss: 0.0004 | training accuracy: 99.33 %\n",
            "Epoch [29/30], Step [200/234], Loss: 0.0039 | training accuracy: 99.33 %\n",
            "Epoch [29/30], Step [400/234], Loss: 0.0319 | training accuracy: 99.39 %\n",
            "Epoch [30/30], Step [200/234], Loss: 0.0247 | training accuracy: 99.39 %\n",
            "Epoch [30/30], Step [400/234], Loss: 0.0404 | training accuracy: 99.39 %\n",
            "Accuracy of the MLP on the 60000 training images: 99.3945 %\n",
            "Accuracy of the MLP on the 10000 test     images: 97.3600 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "batch_size = 128\n",
        "learning_rate = 0.01\n",
        "\n",
        "input_size = 784\n",
        "hidden_size = 32\n",
        "num_classes = 10\n",
        "\n",
        "MLP = Net(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(MLP.parameters(), lr=learning_rate)\n",
        "\n",
        "outputs.append(train_test_evaluate(MLP, num_epochs, batch_size, learning_rate, criterion, optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYbwhotHo8X_",
        "outputId": "7c5dc1ec-3740-4680-bd5d-d14b0bb1903c"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Step [200/468], Loss: 0.1348 | training accuracy: 89.01 %\n",
            "Epoch [1/50], Step [400/468], Loss: 0.2325 | training accuracy: 91.39 %\n",
            "Epoch [2/50], Step [200/468], Loss: 0.1344 | training accuracy: 95.62 %\n",
            "Epoch [2/50], Step [400/468], Loss: 0.1058 | training accuracy: 95.63 %\n",
            "Epoch [3/50], Step [200/468], Loss: 0.1663 | training accuracy: 96.23 %\n",
            "Epoch [3/50], Step [400/468], Loss: 0.1599 | training accuracy: 96.23 %\n",
            "Epoch [4/50], Step [200/468], Loss: 0.1822 | training accuracy: 96.78 %\n",
            "Epoch [4/50], Step [400/468], Loss: 0.1175 | training accuracy: 96.66 %\n",
            "Epoch [5/50], Step [200/468], Loss: 0.1007 | training accuracy: 97.08 %\n",
            "Epoch [5/50], Step [400/468], Loss: 0.0266 | training accuracy: 97.09 %\n",
            "Epoch [6/50], Step [200/468], Loss: 0.0629 | training accuracy: 97.48 %\n",
            "Epoch [6/50], Step [400/468], Loss: 0.1572 | training accuracy: 97.29 %\n",
            "Epoch [7/50], Step [200/468], Loss: 0.0246 | training accuracy: 97.59 %\n",
            "Epoch [7/50], Step [400/468], Loss: 0.1262 | training accuracy: 97.48 %\n",
            "Epoch [8/50], Step [200/468], Loss: 0.0702 | training accuracy: 97.70 %\n",
            "Epoch [8/50], Step [400/468], Loss: 0.1232 | training accuracy: 97.51 %\n",
            "Epoch [9/50], Step [200/468], Loss: 0.1270 | training accuracy: 97.75 %\n",
            "Epoch [9/50], Step [400/468], Loss: 0.0453 | training accuracy: 97.62 %\n",
            "Epoch [10/50], Step [200/468], Loss: 0.0184 | training accuracy: 97.80 %\n",
            "Epoch [10/50], Step [400/468], Loss: 0.0526 | training accuracy: 97.78 %\n",
            "Epoch [11/50], Step [200/468], Loss: 0.0566 | training accuracy: 97.95 %\n",
            "Epoch [11/50], Step [400/468], Loss: 0.0414 | training accuracy: 97.89 %\n",
            "Epoch [12/50], Step [200/468], Loss: 0.1685 | training accuracy: 98.01 %\n",
            "Epoch [12/50], Step [400/468], Loss: 0.0828 | training accuracy: 97.91 %\n",
            "Epoch [13/50], Step [200/468], Loss: 0.1046 | training accuracy: 98.24 %\n",
            "Epoch [13/50], Step [400/468], Loss: 0.0048 | training accuracy: 98.15 %\n",
            "Epoch [14/50], Step [200/468], Loss: 0.1816 | training accuracy: 98.00 %\n",
            "Epoch [14/50], Step [400/468], Loss: 0.0428 | training accuracy: 97.98 %\n",
            "Epoch [15/50], Step [200/468], Loss: 0.1090 | training accuracy: 98.34 %\n",
            "Epoch [15/50], Step [400/468], Loss: 0.1302 | training accuracy: 98.17 %\n",
            "Epoch [16/50], Step [200/468], Loss: 0.0689 | training accuracy: 98.41 %\n",
            "Epoch [16/50], Step [400/468], Loss: 0.1011 | training accuracy: 98.15 %\n",
            "Epoch [17/50], Step [200/468], Loss: 0.0028 | training accuracy: 98.54 %\n",
            "Epoch [17/50], Step [400/468], Loss: 0.0341 | training accuracy: 98.35 %\n",
            "Epoch [18/50], Step [200/468], Loss: 0.0756 | training accuracy: 98.30 %\n",
            "Epoch [18/50], Step [400/468], Loss: 0.0610 | training accuracy: 98.32 %\n",
            "Epoch [19/50], Step [200/468], Loss: 0.0523 | training accuracy: 98.34 %\n",
            "Epoch [19/50], Step [400/468], Loss: 0.1046 | training accuracy: 98.40 %\n",
            "Epoch [20/50], Step [200/468], Loss: 0.1261 | training accuracy: 98.42 %\n",
            "Epoch [20/50], Step [400/468], Loss: 0.0427 | training accuracy: 98.33 %\n",
            "Epoch [21/50], Step [200/468], Loss: 0.0488 | training accuracy: 98.57 %\n",
            "Epoch [21/50], Step [400/468], Loss: 0.0433 | training accuracy: 98.44 %\n",
            "Epoch [22/50], Step [200/468], Loss: 0.0432 | training accuracy: 98.49 %\n",
            "Epoch [22/50], Step [400/468], Loss: 0.1079 | training accuracy: 98.45 %\n",
            "Epoch [23/50], Step [200/468], Loss: 0.0459 | training accuracy: 98.60 %\n",
            "Epoch [23/50], Step [400/468], Loss: 0.1183 | training accuracy: 98.52 %\n",
            "Epoch [24/50], Step [200/468], Loss: 0.0565 | training accuracy: 98.77 %\n",
            "Epoch [24/50], Step [400/468], Loss: 0.0033 | training accuracy: 98.73 %\n",
            "Epoch [25/50], Step [200/468], Loss: 0.0641 | training accuracy: 98.79 %\n",
            "Epoch [25/50], Step [400/468], Loss: 0.0879 | training accuracy: 98.66 %\n",
            "Epoch [26/50], Step [200/468], Loss: 0.0603 | training accuracy: 98.66 %\n",
            "Epoch [26/50], Step [400/468], Loss: 0.0348 | training accuracy: 98.66 %\n",
            "Epoch [27/50], Step [200/468], Loss: 0.0494 | training accuracy: 98.63 %\n",
            "Epoch [27/50], Step [400/468], Loss: 0.0176 | training accuracy: 98.62 %\n",
            "Epoch [28/50], Step [200/468], Loss: 0.0375 | training accuracy: 98.82 %\n",
            "Epoch [28/50], Step [400/468], Loss: 0.0548 | training accuracy: 98.68 %\n",
            "Epoch [29/50], Step [200/468], Loss: 0.0521 | training accuracy: 98.86 %\n",
            "Epoch [29/50], Step [400/468], Loss: 0.0229 | training accuracy: 98.67 %\n",
            "Epoch [30/50], Step [200/468], Loss: 0.0433 | training accuracy: 98.76 %\n",
            "Epoch [30/50], Step [400/468], Loss: 0.0666 | training accuracy: 98.72 %\n",
            "Epoch [31/50], Step [200/468], Loss: 0.0219 | training accuracy: 98.67 %\n",
            "Epoch [31/50], Step [400/468], Loss: 0.0021 | training accuracy: 98.83 %\n",
            "Epoch [32/50], Step [200/468], Loss: 0.0523 | training accuracy: 98.98 %\n",
            "Epoch [32/50], Step [400/468], Loss: 0.0881 | training accuracy: 98.86 %\n",
            "Epoch [33/50], Step [200/468], Loss: 0.0089 | training accuracy: 98.84 %\n",
            "Epoch [33/50], Step [400/468], Loss: 0.0708 | training accuracy: 98.67 %\n",
            "Epoch [34/50], Step [200/468], Loss: 0.0107 | training accuracy: 98.85 %\n",
            "Epoch [34/50], Step [400/468], Loss: 0.0605 | training accuracy: 98.89 %\n",
            "Epoch [35/50], Step [200/468], Loss: 0.0224 | training accuracy: 98.96 %\n",
            "Epoch [35/50], Step [400/468], Loss: 0.0122 | training accuracy: 98.95 %\n",
            "Epoch [36/50], Step [200/468], Loss: 0.0925 | training accuracy: 99.12 %\n",
            "Epoch [36/50], Step [400/468], Loss: 0.0340 | training accuracy: 98.86 %\n",
            "Epoch [37/50], Step [200/468], Loss: 0.0084 | training accuracy: 98.87 %\n",
            "Epoch [37/50], Step [400/468], Loss: 0.1042 | training accuracy: 98.90 %\n",
            "Epoch [38/50], Step [200/468], Loss: 0.0236 | training accuracy: 98.90 %\n",
            "Epoch [38/50], Step [400/468], Loss: 0.0007 | training accuracy: 98.99 %\n",
            "Epoch [39/50], Step [200/468], Loss: 0.0641 | training accuracy: 99.13 %\n",
            "Epoch [39/50], Step [400/468], Loss: 0.1269 | training accuracy: 99.01 %\n",
            "Epoch [40/50], Step [200/468], Loss: 0.0508 | training accuracy: 98.93 %\n",
            "Epoch [40/50], Step [400/468], Loss: 0.1551 | training accuracy: 98.98 %\n",
            "Epoch [41/50], Step [200/468], Loss: 0.0037 | training accuracy: 99.04 %\n",
            "Epoch [41/50], Step [400/468], Loss: 0.0325 | training accuracy: 99.02 %\n",
            "Epoch [42/50], Step [200/468], Loss: 0.0458 | training accuracy: 98.99 %\n",
            "Epoch [42/50], Step [400/468], Loss: 0.0055 | training accuracy: 98.91 %\n",
            "Epoch [43/50], Step [200/468], Loss: 0.0902 | training accuracy: 99.36 %\n",
            "Epoch [43/50], Step [400/468], Loss: 0.0628 | training accuracy: 99.17 %\n",
            "Epoch [44/50], Step [200/468], Loss: 0.0574 | training accuracy: 99.23 %\n",
            "Epoch [44/50], Step [400/468], Loss: 0.0443 | training accuracy: 99.06 %\n",
            "Epoch [45/50], Step [200/468], Loss: 0.1376 | training accuracy: 98.84 %\n",
            "Epoch [45/50], Step [400/468], Loss: 0.1578 | training accuracy: 98.92 %\n",
            "Epoch [46/50], Step [200/468], Loss: 0.0009 | training accuracy: 99.18 %\n",
            "Epoch [46/50], Step [400/468], Loss: 0.0893 | training accuracy: 99.02 %\n",
            "Epoch [47/50], Step [200/468], Loss: 0.0046 | training accuracy: 99.29 %\n",
            "Epoch [47/50], Step [400/468], Loss: 0.0025 | training accuracy: 99.16 %\n",
            "Epoch [48/50], Step [200/468], Loss: 0.0126 | training accuracy: 99.20 %\n",
            "Epoch [48/50], Step [400/468], Loss: 0.0056 | training accuracy: 99.14 %\n",
            "Epoch [49/50], Step [200/468], Loss: 0.1506 | training accuracy: 99.16 %\n",
            "Epoch [49/50], Step [400/468], Loss: 0.0999 | training accuracy: 99.12 %\n",
            "Epoch [50/50], Step [200/468], Loss: 0.0172 | training accuracy: 99.17 %\n",
            "Epoch [50/50], Step [400/468], Loss: 0.0015 | training accuracy: 99.11 %\n",
            "Accuracy of the MLP on the 60000 training images: 99.1094 %\n",
            "Accuracy of the MLP on the 10000 test     images: 96.0100 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusão"
      ],
      "metadata": {
        "id": "Hgu5a8DSgChB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_frame = pd.DataFrame(outputs, columns=[\"hidden layer size\", \"epochs\", \"batch size\", \"learning rate\", \"loss function\", \"optimizer\", \"train accuracy\", \"test accuracy\", \"fit time\"])\n",
        "\n",
        "output_frame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "ydJcdD2Ea8vx",
        "outputId": "48da8a9c-1ea4-4178-ce77-4e2e5ac85ec6"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    hidden layer size  epochs  batch size  learning rate  \\\n",
              "0                 500       5         128          0.001   \n",
              "1                 500       5         128          0.001   \n",
              "2                 500       5         128          0.010   \n",
              "3                 500       5         128          0.010   \n",
              "4                 256       5         128          0.001   \n",
              "5                 256       5         128          0.010   \n",
              "6                 256       5         128          0.010   \n",
              "7                 128       5         128          0.010   \n",
              "8                  64       5         128          0.010   \n",
              "9                  64      10         128          0.010   \n",
              "10                 64      15         128          0.010   \n",
              "11               1028       2         128          0.010   \n",
              "12               1028       2          64          0.010   \n",
              "13                128      10         512          0.010   \n",
              "14                 64      10          32          0.010   \n",
              "15                128      30         256          0.010   \n",
              "16                 32      50         128          0.010   \n",
              "\n",
              "                                       loss function  \\\n",
              "0   <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "1   <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "2   <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "3   <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "4   <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "5   <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "6   <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "7   <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "8   <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "9   <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "10  <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "11  <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "12  <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "13  <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "14  <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "15  <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "16  <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
              "\n",
              "                                optimizer train accuracy test accuracy  \\\n",
              "0           <class 'torch.optim.sgd.SGD'>      74.3965 %     76.0200 %   \n",
              "1         <class 'torch.optim.adam.Adam'>      98.7559 %     97.9100 %   \n",
              "2           <class 'torch.optim.sgd.SGD'>      89.1738 %     90.1400 %   \n",
              "3         <class 'torch.optim.adam.Adam'>      97.9570 %     97.3500 %   \n",
              "4           <class 'torch.optim.sgd.SGD'>      73.7422 %     75.5300 %   \n",
              "5         <class 'torch.optim.adam.Adam'>      97.9746 %     96.9900 %   \n",
              "6   <class 'torch.optim.adagrad.Adagrad'>      97.1172 %     96.8400 %   \n",
              "7         <class 'torch.optim.adam.Adam'>      97.9102 %     96.5700 %   \n",
              "8         <class 'torch.optim.adam.Adam'>      97.6426 %     96.6700 %   \n",
              "9         <class 'torch.optim.adam.Adam'>      98.5664 %     97.1400 %   \n",
              "10        <class 'torch.optim.adam.Adam'>      98.7598 %     96.9900 %   \n",
              "11        <class 'torch.optim.adam.Adam'>      96.5938 %     96.8300 %   \n",
              "12        <class 'torch.optim.adam.Adam'>      96.6875 %     96.8500 %   \n",
              "13        <class 'torch.optim.adam.Adam'>      98.6133 %     97.2400 %   \n",
              "14        <class 'torch.optim.adam.Adam'>      98.2637 %     96.8100 %   \n",
              "15        <class 'torch.optim.adam.Adam'>      99.3945 %     97.3600 %   \n",
              "16        <class 'torch.optim.adam.Adam'>      99.1094 %     96.0100 %   \n",
              "\n",
              "      fit time  \n",
              "0    38.74969s  \n",
              "1    49.57635s  \n",
              "2    38.82370s  \n",
              "3    48.72583s  \n",
              "4    35.68521s  \n",
              "5    42.90964s  \n",
              "6    37.27072s  \n",
              "7    35.83737s  \n",
              "8    33.79173s  \n",
              "9    74.64287s  \n",
              "10  117.85605s  \n",
              "11   27.79571s  \n",
              "12   26.14941s  \n",
              "13   72.49294s  \n",
              "14   66.99576s  \n",
              "15  224.09576s  \n",
              "16  335.85071s  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c35cda7-6b39-44a7-80b1-e720993b0bc8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hidden layer size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>batch size</th>\n",
              "      <th>learning rate</th>\n",
              "      <th>loss function</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>train accuracy</th>\n",
              "      <th>test accuracy</th>\n",
              "      <th>fit time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>500</td>\n",
              "      <td>5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.001</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
              "      <td>74.3965 %</td>\n",
              "      <td>76.0200 %</td>\n",
              "      <td>38.74969s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>500</td>\n",
              "      <td>5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.001</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "      <td>98.7559 %</td>\n",
              "      <td>97.9100 %</td>\n",
              "      <td>49.57635s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>500</td>\n",
              "      <td>5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.010</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
              "      <td>89.1738 %</td>\n",
              "      <td>90.1400 %</td>\n",
              "      <td>38.82370s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>500</td>\n",
              "      <td>5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.010</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "      <td>97.9570 %</td>\n",
              "      <td>97.3500 %</td>\n",
              "      <td>48.72583s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>256</td>\n",
              "      <td>5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.001</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
              "      <td>73.7422 %</td>\n",
              "      <td>75.5300 %</td>\n",
              "      <td>35.68521s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>256</td>\n",
              "      <td>5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.010</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "      <td>97.9746 %</td>\n",
              "      <td>96.9900 %</td>\n",
              "      <td>42.90964s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>256</td>\n",
              "      <td>5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.010</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.adagrad.Adagrad'&gt;</td>\n",
              "      <td>97.1172 %</td>\n",
              "      <td>96.8400 %</td>\n",
              "      <td>37.27072s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>128</td>\n",
              "      <td>5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.010</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "      <td>97.9102 %</td>\n",
              "      <td>96.5700 %</td>\n",
              "      <td>35.83737s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>64</td>\n",
              "      <td>5</td>\n",
              "      <td>128</td>\n",
              "      <td>0.010</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "      <td>97.6426 %</td>\n",
              "      <td>96.6700 %</td>\n",
              "      <td>33.79173s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>64</td>\n",
              "      <td>10</td>\n",
              "      <td>128</td>\n",
              "      <td>0.010</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "      <td>98.5664 %</td>\n",
              "      <td>97.1400 %</td>\n",
              "      <td>74.64287s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>64</td>\n",
              "      <td>15</td>\n",
              "      <td>128</td>\n",
              "      <td>0.010</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "      <td>98.7598 %</td>\n",
              "      <td>96.9900 %</td>\n",
              "      <td>117.85605s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1028</td>\n",
              "      <td>2</td>\n",
              "      <td>128</td>\n",
              "      <td>0.010</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "      <td>96.5938 %</td>\n",
              "      <td>96.8300 %</td>\n",
              "      <td>27.79571s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1028</td>\n",
              "      <td>2</td>\n",
              "      <td>64</td>\n",
              "      <td>0.010</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "      <td>96.6875 %</td>\n",
              "      <td>96.8500 %</td>\n",
              "      <td>26.14941s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>128</td>\n",
              "      <td>10</td>\n",
              "      <td>512</td>\n",
              "      <td>0.010</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "      <td>98.6133 %</td>\n",
              "      <td>97.2400 %</td>\n",
              "      <td>72.49294s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>64</td>\n",
              "      <td>10</td>\n",
              "      <td>32</td>\n",
              "      <td>0.010</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "      <td>98.2637 %</td>\n",
              "      <td>96.8100 %</td>\n",
              "      <td>66.99576s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>128</td>\n",
              "      <td>30</td>\n",
              "      <td>256</td>\n",
              "      <td>0.010</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "      <td>99.3945 %</td>\n",
              "      <td>97.3600 %</td>\n",
              "      <td>224.09576s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>32</td>\n",
              "      <td>50</td>\n",
              "      <td>128</td>\n",
              "      <td>0.010</td>\n",
              "      <td>&lt;class 'torch.nn.modules.loss.CrossEntropyLoss'&gt;</td>\n",
              "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
              "      <td>99.1094 %</td>\n",
              "      <td>96.0100 %</td>\n",
              "      <td>335.85071s</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c35cda7-6b39-44a7-80b1-e720993b0bc8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c35cda7-6b39-44a7-80b1-e720993b0bc8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c35cda7-6b39-44a7-80b1-e720993b0bc8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a462573-37f2-47ee-8666-b2ac31138cd4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a462573-37f2-47ee-8666-b2ac31138cd4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a462573-37f2-47ee-8666-b2ac31138cd4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os testes mostram que o otimizador Adam é inegavelmente a melhor opção para o cenário. Mostra resultados melhores quando comparado ao Adagrada e ao SGD. Além de que não demonstra aumento de complexidade temporal.  \n",
        "\n",
        "Para avaliar o tamanho da camada escondida é preciso levar em consideração a complexidade espacial. Os resultados tendem a relacionar o aumento da camada escondida com o aumento da precisão no conjunto de teste.  \n",
        "\n",
        "É interessante perceber que um aumento na epoch além de 5 mantendo uma quantidade elevada de camadas escondidas não parece trazer um aumento significativo para a precisão no caso da utilização do Adam.  \n",
        "\n",
        "É possível fazer um tradeoff entre o tamanho da camada escondida, quantidade de epochs e tempo de fit. Diminuindo significativamente o tamanho da camada e aumentando a quantidade de epochs causa um aumento no tempo de fit porém gera uma melhora de precisão. Isso é interessante para casos onde a complexidade espacial é importante."
      ],
      "metadata": {
        "id": "H3uxe-j1ltRl"
      }
    }
  ]
}